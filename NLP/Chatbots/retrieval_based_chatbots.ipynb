{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cccc709-e41c-4c24-ac39-a1170da81edf",
   "metadata": {},
   "source": [
    "## Introduction to Retrieval-based Chatbots\r\n",
    "Most modern technology users are well-aware that the voice assistant on their phone is an intelligent chatbot mimicking a human conversation. Less obvious are the thousands of other chatbots that facilitate shopping online, accessing your bank account, and a multitude of other customer-service interactions. In sheer number, retrieval-based chatbots are the most popular chatbot implementation in use today. This popularity is due in large part to the strength of retrieval-based bots in closed-domain conversations — conversations that are clearly limited in scope\n",
    ".\n",
    "\r\n",
    "Most chatbot systems, including those that are retrieval-based, depend on three main tasks in order to convincingly complete a conversati\n",
    "- **Intent Classification:** When presented with user input, a system must classify the intent of the message. Is a message requesting information on the material of a pair of pants for sale? Or is the message related to the estimated shipping date of the clothing item\n",
    "- **\n",
    "Entity Recognition**: Entities are often the proper nouns of a message, like the day of the week when an item will ship, or the name of a specific item of clothing. A chatbot system must be able to recognize which entities a user message revolves around, and reference those entities in a response\n",
    "- **\r\n",
    "Response Selectio**n: Retrieval-based chatbot systems are unique in their reliance on a collection of predefined responses to user messages. Once a system has an understanding of both the intent and main entities of the user message, the program can retrieve the best-fit response from this collection.\n",
    "\n",
    "- When a chatbot receives a user message, intent classification and entity recognition programs are immediately run in tandem.\n",
    "- \n",
    "The results from both of these tasks are then fed into a candidate response generator. In a retrieval-based chatbot system, response generation relies on a database of predefined responses. Using the results from entity recognition and intent classification tasks, a set of possibly similar chatbot responses are retrieved from the database\n",
    "- \r\n",
    "After the selection of a set of candidate responses, a final response selection program ranks and selects the “best fit” response to be returned to the u\n",
    "\n",
    "### Intent with Bag-of-Words\n",
    "------------------------\n",
    "\n",
    "One way we can begin parsing a user’s message to a retrieval-based chatbot is to consider a user’s intent word by word. Bag-of-Words (BoW) is one of the most common models used to understand human language at the individual word level. You might remember that BoW results in a mapping of a word to its frequency in a text.\n",
    "\n",
    "The collections module’s Counter() concisely builds this word-to-frequency mapping:\n",
    "\n",
    "```\n",
    "Counter(preprocess(\"Wheels on the bus go round and round, round and round, round and round.\"))\n",
    "\n",
    "print(word_counts)\n",
    "#Counter({'round': 6, 'wheels': 1, 'bus': 1, 'go': 1})\n",
    "```\n",
    "We can use the results of this mapping to construct a measure of the intent of a user’s message. Then we’ll use this measure to retrieve the most similar answer from our collection of predefined chatbot responses.\n",
    "\n",
    "However, there are a number of different ways in which we can define sentence similarity. There is no guarantee that one definition will be best, or even that any two definitions will suggest the same response!\n",
    "\n",
    "A simple BoW model is best-fit for a situation where the order of words does not contain much information about the intent of a user’s message. In these situations, the unique collection of words in a message often reveals a lot of information about the user’s concern and provides a simple, yet powerful metric to quantify similarity.\n",
    "\n",
    "1.we’ve included user_message, a message sent by a user interacting with a chatbot from an online clothing store. In addition, two possible responses, response_a and response_b, are preprocessed and stored in list data structures.\r\n",
    "se\r\n",
    "2.\r\n",
    "Below where bow_user_message is defined, use the collections module’s Counter() function to build BoW models from the possible response objects. Save the output from the function call on response_a and response_b to bow_response_a and bow_response_b, respecti\n",
    " 3Passed\r\n",
    "3.\r\n",
    "We’ve started writing a short function, called compare_overlap(), to help us compute the number of shared words between our user message and possibleresponses.\r\n",
    "\r\n",
    "After the initialization of similar_words to 0, iterate over each token in user_message and check if the token is already in the possile_response.\r\n",
    "\r\n",
    "If it is, increment similar_words by 1\r\n",
    "Otherwise, do not change the similar_words variable, as the token is not shared between the mess\n",
    "\n",
    "Chckpoint 4 Passed\r\n",
    "4.\r\n",
    "Use compare_overlap() to compare the number of shared words between bow_user_message and both bow_response_a and bow_response_b. Which response is most similar to the user message, based on shared words? Print to console the result of calling compare_overlap() on bow_user_message and the response most similar to the user message.ser.ection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb53596-dad1-4145-936d-075f379abaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk\n",
    "#! pip install scikit-learn\n",
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474cf229-4858-4b44-8451-6cf0f9bd86dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'fit', 'elosie', 'dress', 'shoulders', 'broad', 'often', 'size', 'comfortable', 'fit', 'dress', 'sizes', 'run', 'large', 'small', 'especially', 'shoulders']\n",
      "Number of shared words between user_message and response_a: 1\n",
      "Number of shared words between user_message and response_b: 5\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from preprocess_tokenize import preprocess\n",
    "\n",
    "user_message = preprocess(\"Hello! What is the fit of the 'Elosie' dress? My shoulders are broad, so I often size up for a comfortable fit. Do dress sizes run large or small? Especially in the shoulders?\")\n",
    "response_a = preprocess(\"All of our dresses are cut from a polyester blend for a strechy fit\")\n",
    "response_b = preprocess(\"The 'Elosie' dress runs large. I suggest you take your regular size or smaller for the best fit.\")\n",
    "\n",
    "#printing the user_message variable below\n",
    "print(user_message)\n",
    "\n",
    "#use the Counter() function on the response objects below\n",
    "bow_user_message = Counter(user_message)\n",
    "bow_response_a = Counter(response_a)\n",
    "bow_response_b = Counter(response_b)\n",
    "\n",
    "def compare_overlap(user_message, possible_response):\n",
    "  similar_words = 0\n",
    "  #iterate over tokens in user_message\n",
    "  for token in possible_response:\n",
    "    if token in user_message:\n",
    "      similar_words += 1\n",
    "  return similar_words\n",
    "\n",
    "print(\"Number of shared words between user_message and response_a: \" + str(compare_overlap(bow_user_message, bow_response_a)))\n",
    "print(\"Number of shared words between user_message and response_b: \" + str(compare_overlap(bow_user_message, bow_response_b)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f45da-2e4b-4474-b3be-41be3400125c",
   "metadata": {},
   "source": [
    "### Intent with TF-IDF\r",
    "---\n",
    "While the number of shared words is an intuitive way to think about the similarity between two documents, a number of other methods are also commonly used to determine the best match between the user input and a pre-defined response.\r\n",
    "\r\n",
    "One notable measure, term frequency–inverse document frequency (tf-idf), puts emphasis on the relative frequency in which a term occurs within a possible response and the user message. You can dive into the calculation in our lesson on TF-IDF, but generally, tf-idf is best suited for domains where the most important terms in an input or response are mentioned repeatedly.\r\n",
    "\r\n",
    "In Python, the sklearn package has a handy TfidfVectorizer() object that can be initialized as follo`ws:\r\n",
    "\r\n",
    "vectorizer = TfidfVecto`rizer()\r\n",
    "\r\n",
    "We can then fit the tf-idf model with the .fit_transform() method and input a list of string objects. Using the vectorized results of this fitted model, we can compute the cosine similarity of the user message and a possible response with the aptly named cosine_similarity() f```unction:\r\n",
    "\r\n",
    "# fit model\r\n",
    "tfidf_vectors = vectorizer.fit_transform(input_list)\r\n",
    "\r\n",
    "# compute cosine similarity \r\n",
    "cosine_sim = cosine_similarity(user_message_vector, re```sponse_vector)\r\n",
    "\r\n",
    "Most retrieval-based chatbots use multiple measures in order to rank the similarity between a user’s input and a number of possible responses. Oftentimes, different measures produce different similarity rankings.\r\n",
    "\r\n",
    "The selection of a similarity measure is one of the most important decisions chatbot architects have to make while building a system. We should always consider the relative strengths and weaknesses of different metrics.\r\n",
    "\r\n",
    "Let’s use tf-idf similarity to determine the best match between user_message and a set of possible responses from the earlier exercise; how might this impact which pre-defined response we determine to have the most similar intent with the user message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65fd56b2-e636-4dcc-a792-062c43f15405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 'Elosie' dress runs large. I suggest you take your regular size or smaller.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from preprocessing_pos import preprocess_text \n",
    "\n",
    "response_a = \"Every dress style is cut from a polyester blend for a strechy fit.\"\n",
    "response_b = \"The 'Elosie' dress runs large. I suggest you take your regular size or smaller.\"\n",
    "response_c = \"The 'Elosie' dress comes in green, lavender, and orange.\"\n",
    "user_message = \"Hello! What is the fit of the 'Elosie' dress? My shoulders are broad, so I often size up for a comfortable fit. Do dress sizes run large or small?\"\n",
    "\n",
    "documents = [response_a,response_b,response_c,user_message]\n",
    "\n",
    "# preprocess responses and user_message:\n",
    "processed_docs = [preprocess_text(document) for document in documents]\n",
    "# create tfidf vectorizer:\n",
    "vectorizer = TfidfVectorizer()\n",
    "# fit and transform vectorizer on processed docs:\n",
    "tfidf_vectors = vectorizer.fit_transform(processed_docs)\n",
    "# compute cosine similarity betweeen the user message tf-idf vector and the different response tf-idf vectors:\n",
    "'''Call cosine_similarity() with tfidf_vectors[-1] (user_message) and tfidf_vectors as arguments. \n",
    "This call computes the lexical distance between our user message and each element in tfidf_vectors.'''\n",
    "cosine_similarities = cosine_similarity(tfidf_vectors[-1],tfidf_vectors)\n",
    "\n",
    "# get the index of the most similar response to the user message:\n",
    "'''\n",
    "Call the .argsort() method on cosine_similarities, using slicing notation to only select the data at the 0 index in the object. \n",
    "argsort() is a function from the NumPy package which sorts an array and returns the indices in order.\n",
    "Use another slicing operation to select the response object with the highest similarity score, which is stored at index -2. \n",
    "The user_message itself will always have the highest similarity score, and will always be stored at index -1.'''\n",
    "similar_response_index = cosine_similarities.argsort()[0][-2]\n",
    "best_response = documents[similar_response_index]\n",
    "best_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646c4c0-a382-430e-95f4-d687d32cfa42",
   "metadata": {},
   "source": [
    "### Entity Recognition with POS Tagging\n",
    "---\r\n",
    "After determining the best method for the classification of a user’s intent, chatbot architects set upon the task of recognizing entities within a user’s message. Similar to other tasks in chatbot systems, there are a number of methods that can be used to locate and interpret the entities found in a user message — it is up to the system architect (you!) to critically evaluate methods and select those that are best-fit for a chatbot’s specific domain.\r\n",
    "\r\n",
    "Part of speech (POS) tagging is commonly used to identify entities within a user message, as most entities are nouns (refresh your understanding of English parts of speech in our Parsing with Regex lesson). nltk’s pos_tag() function can rapidly tag a tokenized sentence and return a list of tuple objects for use in entity recognition tasks. A sentence, like “Jack and Jill went up the hill,” when tokenized and supplied in a call to pos_tag(), outputs a list of tuple objects:\r\n",
    "\r\n",
    "tagged_message = [('Jack', 'NNP'), ('and', 'CC'), ('Jill', 'NNP'), ('went', 'VBD'), ('up', 'RP'), ('the', 'DT'), ('hill', 'NN')]\r\n",
    "\r\n",
    "We can extract words tagged as a noun, represented in nltk‘s tagging schema as a collection of tags beginning with “NN,” by checking if the string “NN” occurs in the token tag, and then appending the token string to a list of nouns if True:\r\n",
    "\r\n",
    "for token in tagged_message:\r\n",
    "  if \"NN\" in token[1]:\r\n",
    "     message_nouns.append(token[0])\r\n",
    "\r\n",
    "Once we have a list of the entities in a user message, we’re well on our way to developing a realistic chatbot response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a5a4edf-b455-4bef-b8b7-424bc69a6567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t-shirts', 'weekend', 'package']\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "user_message = [\"i\", \"ordered\", \"two\", \"t-shirts\", \"this\", \"past\", \"weekend\", \"when\",\"will\", \"my\", \"package\", \"be\", \"shipped\"]\n",
    "\n",
    "#define `tagged_user_message` here\n",
    "tagged_user_message = pos_tag(user_message)\n",
    "\n",
    "\n",
    "def extract_nouns(tagged_message):\n",
    "  message_nouns = list()\n",
    "  for token in tagged_user_message:\n",
    "    if \"NN\" in token[1]:\n",
    "      message_nouns.append(token[0])\n",
    "  return message_nouns\n",
    "\n",
    "#define `user_message_nouns` here\n",
    "user_message_nouns = extract_nouns(tagged_user_message)\n",
    "print(user_message_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186ba9f7-784c-4b7a-8b84-14a945e14352",
   "metadata": {},
   "source": [
    "### Entity Recognition with Word Embeddings\n",
    "---\r\n",
    "A conversation is a two-way street — both participants must actively listen to one another and adapt their responses based on the information given by the other. While POS tagging allows us to extract key entities in a user message, it does not provide context that allows a chatbot to believably integrate an entity reference into a predefined response.\r\n",
    "\r\n",
    "A retrieval-based chatbot’s collection of predefined responses is very similar to an empty Madlibs story. Each response is a complete sentence, but with many key words replaced with blank spots. Unlike Madlibs, these blanks will be labeled with a reference to a broad kind of entity. For instance, a predefined response for a weather report chatbot might look like:mad_libs_example\r\n",
    "\r\n",
    "In order to produce a coherent response, the chatbot must insert entities from a user message into these blank spots. Chatbot architects often use word embedding models, like word2vec, to rank the similarity of user-provided entities and the broad category associated with a response “blank spot” (refresh your understanding of word2vec in our word embeddings lesson). The spacy package provides a pre-trained word2vec model which can be called on a string of entities and the responses category like t```his:\r\n",
    "\r\n",
    "# load word2vec model\r\n",
    "word2vec = spacy.load('en')\r\n",
    "\r\n",
    "# call model on data\r\n",
    "tokens = word2vec(\"wednesday, dog, boots, flower\")\r\n",
    "response_category = word2vec```(\"weekday\")\r\n",
    "\r\n",
    "After the model has been applied, we can use spacy’s .similarity() method to compute the cosine similarity between user-provided entities and a respo```nse category:\r\n",
    "\r\n",
    "output_list = list()\r\n",
    "for token in tokens:\r\n",
    "    output_list.append(f\"{token.text} {response_category.text} {token.similarity(response_category)}\")\r\n",
    "\r\n",
    "# output:\r\n",
    "# wednesday weekday 0.453354920245737\r\n",
    "# dog weekday 0.21911001129423147\r\n",
    "# boots weekday 0.15690609198936833\r\n",
    "# flower week```day 0.17118961389940174\r\n",
    "\r\n",
    "The resulting output above shows that the word2vec model found “wednesday” to have the greatest similarity to “weekday.” This should match what you would expect! A chatbot system can select the token with the highest similarity score and insert it into the “blank spot” in a predefined response in order to continue a coherent conversation with a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef42193f-66b7-4877-82c5-2a6359ff4f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! I just checked my records, your shipment containing shirts is en route. Expect it within the next two days!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "word2vec = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "message_nouns = ['shirts', 'weekend', 'package']\n",
    "\n",
    "#define `tokens` and `category`below\n",
    "#Call word2vec() on the string \"clothes\" and assign the result to category.\n",
    "#Call word2vec() on the concatenated form of message_nouns and assign the result to tokens.\n",
    "tokens = word2vec(\" \".join(message_nouns))\n",
    "category = word2vec(\"clothes\")\n",
    "\n",
    "def compute_similarity(tokens, category):\n",
    "  output_list = list()\n",
    "  winner = ''\n",
    "  score = 0\n",
    "  for token in tokens:\n",
    "    result = f'{token} {category} {token.similarity(category)}'\n",
    "    if token.similarity(category) > score:\n",
    "      score = token.similarity(category)\n",
    "      winner = token\n",
    "    # originally the exercise returned a list of tokens, category and the similarity rate\n",
    "    # I decided to return only the best matching token\n",
    "    output_list.append(result)\n",
    "  #it needs to cast to str, because it is a spacy object\n",
    "  return str(winner)\n",
    "winner = compute_similarity(tokens,category)\n",
    "\n",
    "blank_spot = message_nouns[message_nouns.index(winner)]\n",
    "bot_response = f\"Hey! I just checked my records, your shipment containing {blank_spot} is en route. Expect it within the next two days!\"\n",
    "print(bot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df78bf8f-cc7e-4277-ade6-4df7a66be5aa",
   "metadata": {},
   "source": [
    "### Response Selection\r\n",
    "Great work! We’ve covered all the steps necessary for the construction of a chatbot response selection system — now let’s put our skills to work. Using BoW for intent selection, and word2vec for entity recognition, let’s automate the selection of the best-fit response from a collection of candidate responses.\r\n",
    "\r\n",
    "All of the functions defined across previous exercises have been imported into the workspace. In addition, there are four provided data sources:\r\n",
    "\r\n",
    "The user_message, a question from a user engaging with a weather chatbot.\r\n",
    "Three possible response objects, with an entity blank_spot representing an “Illinois” cate\n",
    "gory.\r\n",
    "We’ve already preprocessed the user_message and response objects, and saved the results as BoW models. The results of calling our compare_overlap() function on each candidate response have been saved in similarity_list.\r\n",
    "\r\n",
    "Similarly, a word2vec model has already been fit on our data, and the results of the model have been saved in word2vec_result. It’s up to you to combine the results from both models to retrieve a response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfdf35f9-2d2f-48ea-bcb9-e500f2de878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 'JJ'), ('morning', 'NN'), ('rain', 'NN'), ('chicago', 'NN'), ('later', 'RB'), ('week', 'NN')]\n",
      "Forget about your umbrella; there is no rain forecasted in chicago this weekend.\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "\n",
    "user_message = \"Good morning... will it rain in Chicago later this week?\"\n",
    "\n",
    "blank_spot = \"illinois city\"\n",
    "response_a = \"The average temperature this weekend in {} with be 88 degrees. Bring your sunglasses!\"\n",
    "response_b = \"Forget about your umbrella; there is no rain forecasted in {} this weekend.\"\n",
    "response_c = \"This weekend, a warm front from the southeast will keep skies near {} clear.\"\n",
    "responses= [response_a, response_b, response_c]\n",
    "\n",
    "#preprocess documents\n",
    "bow_user_message = Counter(preprocess(user_message))\n",
    "processed_responses = [Counter(preprocess(response)) for response in responses]\n",
    "\n",
    "#determine intent with BoW\n",
    "#Use Python’s .index() method to select the index of the highest similarity score in similarity_list. We can use the max() function to select the largest element. Save the result of .index() to response_index.\n",
    "similarity_list = [compare_overlap(doc, bow_user_message) for doc in processed_responses]\n",
    "response_index = similarity_list.index(max(similarity_list))\n",
    "\n",
    "#word2vec here is used to slect the entity to replace the blank_spot in the response\n",
    "#extract entities with word2vec \n",
    "tagged_user_message = pos_tag(preprocess(user_message))\n",
    "message_nouns = extract_nouns(tagged_user_message)\n",
    "\n",
    "#execute word2vec below\n",
    "tokens = word2vec(\" \".join(message_nouns))\n",
    "category = word2vec(blank_spot)\n",
    "entity = compute_similarity(tokens, category)\n",
    "\n",
    "#This is a way to select the entity with the highest similarity\n",
    "'''def find_entities(self, user_message):\n",
    "    tagged_user_message = pos_tag(preprocess(user_message))\n",
    "    message_nouns = extract_nouns(tagged_user_message)\n",
    "    \n",
    "    # execute word2vec model here:\n",
    "    tokens = word2vec(' '.join(message_nouns))\n",
    "    category = word2vec(blank_spot)\n",
    "    word2vec_result = compute_similarity(tokens, category)\n",
    "    word2vec_result.sort(key=lambda x: x[2])\n",
    "    return word2vec_result[-1][0]'''\n",
    "\n",
    "#select final response below\n",
    "#the preprocess made all nouns lowercase, it is a bit disturbing in the response\n",
    "final_response = responses[response_index].format(entity)\n",
    "print(final_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b889fc-902e-4969-a665-fd5d49b8c5e9",
   "metadata": {},
   "source": [
    "### Building a Retrieval System\r\n",
    "Now that we have covered the three underlying tasks of a chatbot system — intent classification, entity extraction, and response selection — it’s time for us to pull all these tasks together into a full conversational system! We’ll do so by integrating the functions we have written throughout this lesson into three methods and organize them into a class.\r\n",
    "\r\n",
    "This organization will allow us to call our program from the bash terminal and pass in our own questions as the user_message. We have already included code that initializes and starts a conversation with our bot. It’s up to you to construct the .find_intent_match(), .find_entities(), and .respond() methods so that our bot can really speak!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c010514-5dfc-4f78-8d5c-1e535e385c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac4714e-f3f5-48e5-b12a-0eb1f6c25b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74880106-2698-4562-a487-91b2e8fcfacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870859ae-47e2-4c95-930d-23a0fc2e54ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9249c1-59d6-4fcd-815d-5c11d088b573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
